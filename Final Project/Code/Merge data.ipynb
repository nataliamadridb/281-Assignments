{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/235939291.py:7: DtypeWarning: Columns (6,8,9,10,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,56,57,58,60,62,63,64,65,66,67,68,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   globalcompanykey   gvkey\n",
      "0              1004  001004\n",
      "1              1004  001004\n",
      "2              1004  001004\n",
      "3              1004  001004\n",
      "4              1004  001004\n",
      "Archivo guardado exitosamente con columna 'gvkey' en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Firm financials_Compustat_with_gvkey.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Define the file path ===\n",
    "file_path = \"/Users/nataliamadrid/Desktop/Micro fact/Firm financials_Compustat.csv\"\n",
    "\n",
    "# === Step 2: Read the CSV file ===\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# === Step 3: Clean column names (remove invisible spaces) ===\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# === Step 4: Rename the identifier column if needed ===\n",
    "# In your file it's called 'Global Company Key', we rename it to make it easier to use\n",
    "df = df.rename(columns={'Global Company Key': 'globalcompanykey'})\n",
    "\n",
    "# === Step 5: Create the 'gvkey' column as a 6-digit string ===\n",
    "df['gvkey'] = df['globalcompanykey'].astype(int).astype(str).str.zfill(6)\n",
    "\n",
    "# === Step 6: Check the transformation (optional) ===\n",
    "print(df[['globalcompanykey', 'gvkey']].head())\n",
    "\n",
    "# === Step 7: Save the new file with the 'gvkey' column included ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Firm financials_Compustat_with_gvkey.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"File successfully saved with 'gvkey' column at:\\n{output_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/3029505942.py:7: DtypeWarning: Columns (6,8,9,10,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,56,57,58,60,62,63,64,65,66,67,68,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fin = pd.read_csv(financials_path)\n",
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/3029505942.py:8: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_loc = pd.read_csv(location_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge exitoso. Archivo guardado en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load the files ===\n",
    "financials_path = \"/Users/nataliamadrid/Desktop/Micro fact/Firm financials_Compustat_with_gvkey.csv\"\n",
    "location_path = \"/Users/nataliamadrid/Desktop/Micro fact/CRSP_Location_firmlevel.csv\"\n",
    "\n",
    "df_fin = pd.read_csv(financials_path)\n",
    "df_loc = pd.read_csv(location_path)\n",
    "\n",
    "# === Step 2: Make sure columns don’t have extra/invisible spaces ===\n",
    "df_fin.columns = df_fin.columns.str.strip()\n",
    "df_loc.columns = df_loc.columns.str.strip()\n",
    "\n",
    "# === Step 3: Convert gvkey to 6-digit string in both datasets ===\n",
    "if 'gvkey' not in df_fin.columns:\n",
    "    df_fin['gvkey'] = df_fin['globalcompanykey'].astype(str).str.zfill(6)\n",
    "\n",
    "if 'gvkey' not in df_loc.columns:\n",
    "    if 'globalcompanykey' in df_loc.columns:\n",
    "        df_loc['gvkey'] = df_loc['globalcompanykey'].astype(str).str.zfill(6)\n",
    "    else:\n",
    "        raise ValueError(\"No column named 'gvkey' or 'globalcompanykey' found in the location file.\")\n",
    "\n",
    "# === Step 4: Ensure gvkey is string type in both datasets ===\n",
    "df_fin['gvkey'] = df_fin['gvkey'].astype(str)\n",
    "df_loc['gvkey'] = df_loc['gvkey'].astype(str)\n",
    "\n",
    "# === Step 5: Merge ===\n",
    "merged_df = pd.merge(df_fin, df_loc, on='gvkey', how='left')\n",
    "\n",
    "# === Step 6: Save the result ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Merge successful. File saved at:\\n{output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/3990873712.py:4: DtypeWarning: Columns (6,7,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,82,99,100,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location.csv\")\n",
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/3990873712.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['date'] = pd.to_datetime(df['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date quarter\n",
      "0 2010-01-31  2010Q1\n",
      "1 2010-02-28  2010Q1\n",
      "2 2010-03-31  2010Q1\n",
      "3 2010-04-30  2010Q2\n",
      "4 2010-05-31  2010Q2\n",
      "✅ Archivo guardado con 'quarter' en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location_with_quarter.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load the file ===\n",
    "df = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location.csv\")\n",
    "\n",
    "# === Clean column names just in case ===\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# === Convert the 'date' column to datetime format ===\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# === Create 'quarter' variable in format like '2010Q1' ===\n",
    "df['quarter'] = df['date'].dt.to_period('Q').astype(str)\n",
    "\n",
    "# Check the result\n",
    "print(df[['date', 'quarter']].dropna().head())\n",
    "\n",
    "# === Save file with the new 'quarter' column ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location_with_quarter.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ File saved with 'quarter' column at:\\n{output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/2763362565.py:4: DtypeWarning: Columns (40,41,42,47,62,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fund = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    datadate quarter\n",
      "0 2010-02-28  2010Q1\n",
      "1 2010-05-31  2010Q2\n",
      "2 2010-08-31  2010Q3\n",
      "3 2010-11-30  2010Q4\n",
      "4 2011-02-28  2011Q1\n",
      "✅ Archivo con quarter calendario guardado en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters_with_quarter_calendario.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Paso 1: Cargar datos ===\n",
    "df_fund = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters.csv\")\n",
    "\n",
    "# === Paso 2: Convertir 'datadate' a datetime y crear quarter calendario ===\n",
    "df_fund['datadate'] = pd.to_datetime(df_fund['datadate'], errors='coerce')\n",
    "df_fund['quarter'] = df_fund['datadate'].dt.to_period('Q').astype(str)\n",
    "\n",
    "# === Paso 3: Verificar resultado ===\n",
    "print(df_fund[['datadate', 'quarter']].head())\n",
    "\n",
    "# === Paso 4: Guardar archivo con quarter corregido ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters_with_quarter_calendario.csv\"\n",
    "df_fund.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Archivo con quarter calendario guardado en:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/4099847627.py:4: DtypeWarning: Columns (6,7,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,82,99,100,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_main = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Merged_Financials_Location_with_quarter.csv\")\n",
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_7792/4099847627.py:5: DtypeWarning: Columns (40,41,42,47,62,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fund = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters_with_quarter_calendario.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge exitoso. Archivo guardado en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_With_Fundamentals_calendario.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load data ===\n",
    "df_fund = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters.csv\")\n",
    "\n",
    "# === Step 2: Convert 'datadate' to datetime and create calendar quarter ===\n",
    "df_fund['datadate'] = pd.to_datetime(df_fund['datadate'], errors='coerce')\n",
    "df_fund['quarter'] = df_fund['datadate'].dt.to_period('Q').astype(str)\n",
    "\n",
    "# === Step 3: Verify result ===\n",
    "print(df_fund[['datadate', 'quarter']].head())\n",
    "\n",
    "# === Step 4: Save file with corrected quarter ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Fundamental_quarters_with_quarter_calendario.csv\"\n",
    "df_fund.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ File with calendar quarter saved to:\\n{output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data merge calendario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_9479/2288136147.py:4: DtypeWarning: Columns (5,6,7,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,82,99,100,102,104,152,153,155,173,174,179,184) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_With_Fundamentals_calendario.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['globalcompanykey', 'historical crsp permno link to compustat record', 'fiscal year end', 'fiscal quarter end', 'date', 'shillers cyclically adjusted p/e ratio', 'book/market', 'enterprise value multiple', 'price/operating earnings (basic, excl. ei)', 'price/operating earnings (diluted, excl. ei)', 'p/e (diluted, excl. ei)', 'p/e (diluted, incl. ei)', 'price/sales', 'price/cash flow', 'dividend payout ratio', 'net profit margin', 'operating profit margin before depreciation', 'operating profit margin after depreciation', 'gross profit margin', 'pre-tax profit margin', 'cash flow margin', 'return on assets', 'return on equity', 'return on capital employed', 'effective tax rate', 'after-tax return on average common equity', 'after-tax return on invested capital', 'after-tax return on total stockholders equity', 'pre-tax return on net operating assets', 'pre-tax return on total earning assets', 'gross profit/total assets', 'common equity/invested capital', 'long-term debt/invested capital', 'total debt/invested capital', 'capitalization ratio', 'interest/average long-term debt', 'interest/average total debt', 'cash balance/total liabilities', 'inventory/current assets', 'receivables/current assets', 'total debt/total assets', 'total debt/ebitda', 'short-term debt/total debt', 'current liabilities/total liabilities', 'long-term debt/total liabilities', 'profit before depreciation/current liabilities', 'operating cf/current liabilities', 'cash flow/total debt', 'free cash flow/operating cash flow', 'total liabilities/total tangible assets', 'long-term debt/book equity', 'total debt/total assets.1', 'total debt/capital', 'total debt/equity', 'after-tax interest coverage', 'interest coverage ratio', 'cash ratio', 'quick ratio (acid test)', 'current ratio', 'cash conversion cycle (days)', 'inventory turnover', 'asset turnover', 'receivables turnover', 'payables turnover', 'sales/invested capital', 'sales/stockholders equity', 'sales/working capital', 'research and development/sales', 'avertising expenses/sales', 'labor expenses/sales', 'accruals/average assets', 'price/book', 'trailing p/e to growth (peg) ratio', 'dividend yield', 'ticker symbol', 'cusip_x', 'gvkey', 'conm_x', 'tic_x', 'sic_x', 'naics_x', 'linkprim', 'liid', 'linktype', 'lpermno', 'lpermco', 'linkdt', 'linkenddt', 'ein_x', 'costat_x', 'priusa_x', 'fic_x', 'loc_x', 'incorp_x', 'state_x', 'county_x', 'city_x', 'conml_x', 'add1_x', 'add2_x', 'add3_x', 'add4_x', 'addzip_x', 'busdesc_x', 'ipodate_x', 'fyrc_x', 'gsector_x', 'ggroup_x', 'gind_x', 'gsubind_x', 'spcindcd_x', 'spcseccd_x', 'quarter', 'datadate', 'fyearq', 'fqtr', 'fyr', 'indfmt', 'consol', 'popsrc', 'datafmt', 'tic_y', 'cusip_y', 'conm_y', 'curcdq', 'datacqtr', 'datafqtr', 'acoq', 'actq', 'altoq', 'ancq', 'anoq', 'atq', 'dvpq', 'intanoq', 'intanq', 'lcoq', 'lctq', 'lltq', 'ltq', 'niq', 'ppentq', 'revtq', 'exchg', 'cik', 'costat_y', 'fic_y', 'cshtrq', 'dvpspq', 'dvpsxq', 'mkvaltq', 'add1_y', 'add2_y', 'add3_y', 'add4_y', 'addzip_y', 'busdesc_y', 'city_y', 'conml_y', 'county_y', 'dlrsn', 'ein_y', 'fax', 'fyrc_y', 'ggroup_y', 'gind_y', 'gsector_y', 'gsubind_y', 'idbflag', 'incorp_y', 'loc_y', 'naics_y', 'phone', 'prican', 'prirow', 'priusa_y', 'sic_y', 'spcindcd_y', 'spcseccd_y', 'spcsrc', 'state_y', 'stko', 'weburl', 'dldte', 'ipodate_y']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load the dataset with calendar quarter ===\n",
    "df = pd.read_csv(\"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_With_Fundamentals_calendario.csv\")\n",
    "\n",
    "# View current columns (optional)\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# === List of columns to drop ===\n",
    "cols_to_drop = [\n",
    "    'salesworkingcapital', 'salesinvestedcapital', 'salesstockholderequity',\n",
    "    'researchanddevelopmentsales', 'avertisingexpensesales',  # <- check if this is a typo\n",
    "    'laborexpensesales', 'accrualsaverageassets',\n",
    "    'assetturnover', 'receivablesturnover', 'payablesturnover', 'inventoryturnover',\n",
    "    'cashratio', 'quickratioacidtest', 'currentratio', 'cashconversioncycledays',\n",
    "    'indfmt', 'consol', 'popsrc', 'datafmt',\n",
    "    'add2_y', 'add3_y', 'add4_y', 'add2_x', 'add3_x', 'add4_x',\n",
    "    'prican', 'prirow',\n",
    "    'pedilutedinclei', 'pedilutedexclei',\n",
    "    'pricesales', 'pricecashflow', 'dividendpayoutratio',\n",
    "    'netprofitmargin', 'operatingprofitmarginbeforedepre', 'operatingprofitmarginafterdeprec',\n",
    "    'grossprofitmargin', 'pretaxprofitmargin', 'cashflowmargin',\n",
    "    'returnonassets', 'returnonequity', 'returnoncapitalemployed',\n",
    "    'effectivetaxrate', 'aftertaxreturnonaveragecommonequ', 'aftertaxreturnoninvestedcapital',\n",
    "    'aftertaxreturnontotalstockholder', 'pretaxreturnonnetoperatingassets',\n",
    "    'pretaxreturnontotalearningassets', 'profitbeforedepreciationcurrentl',\n",
    "    'operatingcfcurrentliabilities', 'cashflowtotaldebt', 'freecashflowoperatingcashflow',\n",
    "    'aftertaxinterestcoverage', 'interestcoverage',\n",
    "    'enterprisevaluemultiple', 'priceoperatingearningsbasicexcle', 'priceoperatingearningsdilutedexc',\n",
    "    'fqtr', 'fyr'\n",
    "]\n",
    "\n",
    "# === Drop columns if they exist ===\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "\n",
    "# === Save cleaned version ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Clean_FINAL.csv\"\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_9479/3445381389.py:7: DtypeWarning: Columns (5,6,7,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,82,99,101,143,165,170) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_panel = pd.read_csv(panel_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merge realizado exitosamente. Archivo guardado en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Final_With_Extra.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load both datasets ===\n",
    "panel_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Clean_FINAL.csv\"\n",
    "extra_path = \"/Users/nataliamadrid/Desktop/Micro fact/datosextra.csv\"\n",
    "\n",
    "df_panel = pd.read_csv(panel_path)\n",
    "df_extra = pd.read_csv(extra_path)\n",
    "\n",
    "# === Step 2: Standardize column names just in case ===\n",
    "df_panel.columns = df_panel.columns.str.strip().str.lower()\n",
    "df_extra.columns = df_extra.columns.str.strip().str.lower()\n",
    "\n",
    "# === Step 3: Check that both key columns exist ===\n",
    "if 'gvkey' not in df_panel.columns or 'datafqtr' not in df_panel.columns:\n",
    "    raise ValueError(\"❌ Columns 'gvkey' and/or 'datafqtr' are missing from df_panel.\")\n",
    "if 'gvkey' not in df_extra.columns or 'datafqtr' not in df_extra.columns:\n",
    "    raise ValueError(\"❌ Columns 'gvkey' and/or 'datafqtr' are missing from df_extra.\")\n",
    "\n",
    "# === Step 4: Perform the merge ===\n",
    "df_merged = pd.merge(df_panel, df_extra, on=['gvkey', 'datafqtr'], how='left')\n",
    "\n",
    "# === Step 5: Save the result ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Final_With_Extra.csv\"\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Merge completed successfully. File saved to:\\n{output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/jnlxvgzn5w9gg8rwqvwlxst80000gn/T/ipykernel_9479/621062630.py:7: DtypeWarning: Columns (5,6,7,8,9,10,11,12,14,15,16,17,18,19,20,22,23,24,25,26,27,28,31,32,33,34,35,36,37,41,45,46,48,49,50,52,53,54,55,56,57,58,59,60,62,63,64,65,66,67,68,69,82,99,101,143,165,170) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Trimmed.csv'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the original file\n",
    "input_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Final_With_Extra.csv\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# List of variables to keep\n",
    "vars_to_keep = [\n",
    "    'gvkey', 'date', 'totaldebttotalassets', 'tickersymbol', 'cusip_x', 'tic_x', 'sic_x',\n",
    "    'naics_x', 'ein_x', 'loc_x', 'state_x', 'city_x', 'conml_x', 'add1_x', 'addzip_x',\n",
    "    'gsector_x', 'ggroup_x', 'quarter', 'datacqtr_x', 'curcdq_x', 'gind_x', 'spcindcd_x',\n",
    "    'spcseccd_x', 'atq_x', 'actq_x', 'altoq', 'lctq', 'lltq', 'ppentq', 'cik', 'cshtrq',\n",
    "    'dlcq', 'dlttq', 'ltq'\n",
    "]\n",
    "\n",
    "# Filter columns\n",
    "df_filtered = df[[col for col in vars_to_keep if col in df.columns]]\n",
    "\n",
    "# Save the trimmed version\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Trimmed.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo con columnas renombradas guardado en:\n",
      "/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Trimmed_Renamed.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load the filtered file ===\n",
    "file_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Trimmed.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# === Rename columns by removing '_x' at the end ===\n",
    "df.columns = df.columns.str.replace('_x$', '', regex=True)\n",
    "\n",
    "# === Save the updated file ===\n",
    "output_path = \"/Users/nataliamadrid/Desktop/Micro fact/Panel_Merged_Trimmed_Renamed.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# ✅ Confirmation message\n",
    "print(f\"✅ File with renamed columns saved at:\\n{output_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
